# ğŸš„ Project Nexline

**Pilot ETL & Visualization Pipeline for Public Transit Schedules**

This repository contains a simple, extensible ETL pipeline to collect, transform, and store daily SEPTA train schedules using
DuckDB, with plans to power a future web-based visualization layer. The project is gitâ€‘managed, CIâ€‘tested, and designed
to scale to multiple agencies.

---

## ğŸš€ Highlights

* **Modular, Layered Architecture**: Clear separation of configuration, extraction, fetching, transformation, loading,
  and orchestration.
* **Extensible Fetchers**: Fetch schedules via API packages under `src/fetchers/`; add new endpoints by dropping in a
  new module.
* **Reliable Data Collection**: Collect script (`collect_train_numbers.py`) runs every 2â€“3 min from 4 AMâ€“1 AM to
  accumulate a full dayâ€™s train numbers.
* **DuckDB Storage**: Lightweight, zeroâ€‘server analytics store; stores both raw schedule snapshots and collected train
  numbers.
* **CLI Orchestration**: `run_etl.py` supports flags for date, dryâ€‘run, verbosity, and concurrency.
* **Automated Testing & CI**: Pytest, flake8 linting, and coverage checks on every push via GitHub Actions.
* **Easy Deployment**: Versioned cronjobs file under `deploy/cronjobs.txt` for automated scheduling.

---

## ğŸ“‚ Repository Structure

```
project-nexline/
â”œâ”€â”€ .github/workflows/ci.yml       # CI pipeline (tests, lint, coverage)
â”œâ”€â”€ config.py                      # Central constants and URLs
â”œâ”€â”€ data/                          # DuckDB database files (gitâ€‘ignored)
â”œâ”€â”€ deploy/cronjobs.txt            # Versioned crontab entries
â”œâ”€â”€ docs/                          # (Future) documentation or design artifacts
â”œâ”€â”€ logs/                          # Cron logs (gitâ€‘ignored)
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ sql/                           # DDL for DuckDB tables
â”‚   â”œâ”€â”€ create_schedules_table.sql
â”‚   â””â”€â”€ create_train_numbers_table.sql
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ collect_train_numbers.py   # Periodic trainâ€‘number collection
â”‚   â”œâ”€â”€ init_db.py                 # Oneâ€‘off DB initialization
â”‚   â””â”€â”€ run_etl.py                 # Nightly ETL orchestration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ db.py                      # DuckDB connection & schema + data access helpers
â”‚   â”œâ”€â”€ extractors.py              # TrainView API extraction
â”‚   â”œâ”€â”€ fetchers/                  # Package of API fetch modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ rrschedules.py         # RRSchedules endpoint
â”‚   â”œâ”€â”€ loader.py                  # Load cleaned records into DuckDB
â”‚   â”œâ”€â”€ transformer.py             # Normalize & validate raw data
â”‚   â””â”€â”€ ...                        # Future extensions
â”œâ”€â”€ tests/                         # Unit tests for all modules
â””â”€â”€ README.md                      # This file
```

---

## âš™ï¸ Getting Started

1. **Clone the repo**

   ```bash
   git clone https://github.com/nathankong97/project-nexline.git
   cd project-nexline
   ```

2. **Set up a virtual environment**

   ```bash
   python3 -m venv .venv
   source .venv/bin/activate   # macOS/Linux
   .venv\Scripts\activate    # Windows PowerShell
   ```

3. **Install dependencies**

   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

4. **Initialize the database**

   ```bash
   python scripts/init_db.py
   ```

5. **Run a dryâ€‘run ETL**

   ```bash
   python scripts/run_etl.py --dry-run
   ```

6. **Inspect data in DuckDB** (via Python REPL or DataGrip)

   ```python
   import duckdb
   conn = duckdb.connect('data/schedules.duckdb')
   print(conn.execute('SELECT * FROM train_numbers LIMIT 5').fetchall())
   ```

---

## ğŸ›  Usage

**Nightly ETL**:

```bash
python3 scripts/run_etl.py [--db-path PATH] [--date YYYY-MM-DD] [--workers N] [--verbose]
```

* `--db-path`: Path to DuckDB file (default: `./.tmp/test.duckdb`)
* `--date`: Target service date (default: yesterday)
* `--workers`: Concurrent fetch threads (default: 10)
* `--dry-run`: Skip writes, only report counts
* `--verbose`: Enable debug logging

**Continuous Collection**:

```bash
python3 scripts/collect_train_numbers.py
```

Run every 2â€“3 minutes (4 AMâ€“2 AM) via cron as defined in `deploy/cronjobs.txt`.

---

## ğŸ¯ Next Milestones

* **Web Visualization**: Integrate an OLAP layer, build a React dashboard to plot delays and schedules.
* **Additional Agencies**: Add fetchers for MTA, NJ Transit, Amtrak, etc.
* **Enhanced Analytics**: Build summary tables, weekly/monthly rollups in DuckDB or BI tools.

---

## ğŸ“„ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.
